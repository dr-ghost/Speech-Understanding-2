{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this to generate mixture dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 mixture.py --vox2_dir data/vox2 --output_dir data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speaker Seperation and Enhancement using SepFormer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the pre-trained SepFormer model to perform speaker separation and speech enhancement of each speaker on the created test set by analyzing these metrics: Signal to Interference Ratio (SIR), Signal to Artefacts Ratio (SAR), Signal to Distortion Ratio (SDR) and Perceptual Evaluation of Speech Quality (PESQ). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raid/anshul/Speech-Understanding-2/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sepformer import *\n",
    "from data import *\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/sepformer-whamr' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/sepformer-whamr' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch masknet.ckpt: Fetching from HuggingFace Hub 'speechbrain/sepformer-whamr' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch encoder.ckpt: Fetching from HuggingFace Hub 'speechbrain/sepformer-whamr' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch decoder.ckpt: Fetching from HuggingFace Hub 'speechbrain/sepformer-whamr' if not cached\n",
      "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: masknet, encoder, decoder\n"
     ]
    }
   ],
   "source": [
    "sepformer = get_sepformer_model('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vox_mix = VoxCelebmix(data_dir='data/vox2_mix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [15:14<00:00,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "metrics_dir = {}\n",
    "\n",
    "for i in tqdm(range(n_samples)):\n",
    "    sample_idx = random.randint(0, len(vox_mix) - 1)\n",
    "    wav_mix, wav_s1, wav_s2, sp1, sp2, _ = vox_mix[sample_idx]\n",
    "    \n",
    "    min_sz = min(wav_s1.shape[-1], wav_s2.shape[-1])\n",
    "    \n",
    "    if wav_s1.shape[-1] > min_sz:\n",
    "        wav_s1 = wav_s1[:, :min_sz]\n",
    "    if wav_s2.shape[-1] > min_sz:\n",
    "        wav_s2 = wav_s2[:, :min_sz]\n",
    "\n",
    "    pred_s1, pred_s2 = speaker_separation(sepformer, wav_mix)\n",
    "\n",
    "    \n",
    "    gt = torch.cat([wav_s1, wav_s2], dim=0).numpy()\n",
    "    pred = torch.cat([pred_s1, pred_s2], dim=0).numpy()\n",
    "    \n",
    "    min_sz = min(gt.shape[-1], pred.shape[-1])\n",
    "    \n",
    "    if gt.shape[-1] > min_sz:\n",
    "        gt = gt[:, :min_sz]\n",
    "    if pred.shape[-1] > min_sz:\n",
    "        pred = pred[:, :min_sz]\n",
    "\n",
    "    sdr, sir, sar, pesq_scores = compute_separation_metrics(gt, pred, sample_rate=16_000)\n",
    "    \n",
    "    if sp1 not in metrics_dir.keys():\n",
    "        metrics_dir[sp1] = [[sdr[0]], [sir[0]], [sar[0]], [pesq_scores[0]]]\n",
    "    else:\n",
    "        metrics_dir[sp1][0].append(sdr[0])\n",
    "        metrics_dir[sp1][1].append(sir[0])\n",
    "        metrics_dir[sp1][2].append(sar[0])\n",
    "        metrics_dir[sp1][3].append(pesq_scores[0])\n",
    "        \n",
    "    if sp2 not in metrics_dir.keys():\n",
    "        metrics_dir[sp2] = [[sdr[1]], [sir[1]], [sar[1]], [pesq_scores[1]]]\n",
    "    else:\n",
    "        metrics_dir[sp2][0].append(sdr[1])\n",
    "        metrics_dir[sp2][1].append(sir[1])\n",
    "        metrics_dir[sp2][2].append(sar[1])\n",
    "        metrics_dir[sp2][3].append(pesq_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = []\n",
    "\n",
    "for k, v in metrics_dir.items():\n",
    "    row = {\n",
    "        \"Key\": k,\n",
    "        \"SIR_MEAN\": np.mean(v[1]), \"SIR_VARIANCE\": np.var(v[1]),\n",
    "        \"SAR_MEAN\": np.mean(v[2]), \"SAR_VARIANCE\": np.var(v[2]),\n",
    "        \"SDR_MEAN\": np.mean(v[0]), \"SDR_VARIANCE\": np.var(v[0]),\n",
    "        \"PESQ_MEAN\": np.mean(v[3]), \"PESQ_VARIANCE\": np.var(v[3]),\n",
    "    }\n",
    "    df_data.append(row)\n",
    "\n",
    "df = pd.DataFrame(df_data)\n",
    "\n",
    "df.set_index(\"Key\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SIR_MEAN</th>\n",
       "      <th>SIR_VARIANCE</th>\n",
       "      <th>SAR_MEAN</th>\n",
       "      <th>SAR_VARIANCE</th>\n",
       "      <th>SDR_MEAN</th>\n",
       "      <th>SDR_VARIANCE</th>\n",
       "      <th>PESQ_MEAN</th>\n",
       "      <th>PESQ_VARIANCE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id00154</th>\n",
       "      <td>10.521380</td>\n",
       "      <td>227.802958</td>\n",
       "      <td>-4.142282</td>\n",
       "      <td>18.451845</td>\n",
       "      <td>-8.231168</td>\n",
       "      <td>81.194939</td>\n",
       "      <td>1.110132</td>\n",
       "      <td>0.004038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00866</th>\n",
       "      <td>6.617601</td>\n",
       "      <td>343.371110</td>\n",
       "      <td>-3.835985</td>\n",
       "      <td>26.908087</td>\n",
       "      <td>-10.557370</td>\n",
       "      <td>118.509879</td>\n",
       "      <td>1.121674</td>\n",
       "      <td>0.040492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01066</th>\n",
       "      <td>8.324409</td>\n",
       "      <td>319.070619</td>\n",
       "      <td>-3.091958</td>\n",
       "      <td>26.173350</td>\n",
       "      <td>-8.877471</td>\n",
       "      <td>108.790636</td>\n",
       "      <td>1.117321</td>\n",
       "      <td>0.008584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00419</th>\n",
       "      <td>0.870727</td>\n",
       "      <td>330.560557</td>\n",
       "      <td>-5.923366</td>\n",
       "      <td>48.326800</td>\n",
       "      <td>-14.635148</td>\n",
       "      <td>157.250794</td>\n",
       "      <td>1.071582</td>\n",
       "      <td>0.002424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01892</th>\n",
       "      <td>-1.816690</td>\n",
       "      <td>254.610565</td>\n",
       "      <td>-8.194641</td>\n",
       "      <td>59.926393</td>\n",
       "      <td>-17.643697</td>\n",
       "      <td>88.353395</td>\n",
       "      <td>1.079743</td>\n",
       "      <td>0.008471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SIR_MEAN  SIR_VARIANCE  SAR_MEAN  SAR_VARIANCE   SDR_MEAN  \\\n",
       "Key                                                                   \n",
       "id00154  10.521380    227.802958 -4.142282     18.451845  -8.231168   \n",
       "id00866   6.617601    343.371110 -3.835985     26.908087 -10.557370   \n",
       "id01066   8.324409    319.070619 -3.091958     26.173350  -8.877471   \n",
       "id00419   0.870727    330.560557 -5.923366     48.326800 -14.635148   \n",
       "id01892  -1.816690    254.610565 -8.194641     59.926393 -17.643697   \n",
       "\n",
       "         SDR_VARIANCE  PESQ_MEAN  PESQ_VARIANCE  \n",
       "Key                                              \n",
       "id00154     81.194939   1.110132       0.004038  \n",
       "id00866    118.509879   1.121674       0.040492  \n",
       "id01066    108.790636   1.117321       0.008584  \n",
       "id00419    157.250794   1.071582       0.002424  \n",
       "id01892     88.353395   1.079743       0.008471  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SIR_MEAN</th>\n",
       "      <th>SIR_VARIANCE</th>\n",
       "      <th>SAR_MEAN</th>\n",
       "      <th>SAR_VARIANCE</th>\n",
       "      <th>SDR_MEAN</th>\n",
       "      <th>SDR_VARIANCE</th>\n",
       "      <th>PESQ_MEAN</th>\n",
       "      <th>PESQ_VARIANCE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id00154</th>\n",
       "      <td>10.521380</td>\n",
       "      <td>227.802958</td>\n",
       "      <td>-4.142282</td>\n",
       "      <td>18.451845</td>\n",
       "      <td>-8.231168</td>\n",
       "      <td>81.194939</td>\n",
       "      <td>1.110132</td>\n",
       "      <td>0.004038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00866</th>\n",
       "      <td>6.617601</td>\n",
       "      <td>343.371110</td>\n",
       "      <td>-3.835985</td>\n",
       "      <td>26.908087</td>\n",
       "      <td>-10.557370</td>\n",
       "      <td>118.509879</td>\n",
       "      <td>1.121674</td>\n",
       "      <td>0.040492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01066</th>\n",
       "      <td>8.324409</td>\n",
       "      <td>319.070619</td>\n",
       "      <td>-3.091958</td>\n",
       "      <td>26.173350</td>\n",
       "      <td>-8.877471</td>\n",
       "      <td>108.790636</td>\n",
       "      <td>1.117321</td>\n",
       "      <td>0.008584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00419</th>\n",
       "      <td>0.870727</td>\n",
       "      <td>330.560557</td>\n",
       "      <td>-5.923366</td>\n",
       "      <td>48.326800</td>\n",
       "      <td>-14.635148</td>\n",
       "      <td>157.250794</td>\n",
       "      <td>1.071582</td>\n",
       "      <td>0.002424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01892</th>\n",
       "      <td>-1.816690</td>\n",
       "      <td>254.610565</td>\n",
       "      <td>-8.194641</td>\n",
       "      <td>59.926393</td>\n",
       "      <td>-17.643697</td>\n",
       "      <td>88.353395</td>\n",
       "      <td>1.079743</td>\n",
       "      <td>0.008471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id02577</th>\n",
       "      <td>0.987114</td>\n",
       "      <td>287.076045</td>\n",
       "      <td>-5.062195</td>\n",
       "      <td>42.158743</td>\n",
       "      <td>-13.372956</td>\n",
       "      <td>122.273652</td>\n",
       "      <td>1.122451</td>\n",
       "      <td>0.011619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id02019</th>\n",
       "      <td>0.602653</td>\n",
       "      <td>278.713769</td>\n",
       "      <td>-5.613182</td>\n",
       "      <td>22.466980</td>\n",
       "      <td>-13.967106</td>\n",
       "      <td>124.655204</td>\n",
       "      <td>1.079537</td>\n",
       "      <td>0.003499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01593</th>\n",
       "      <td>5.811400</td>\n",
       "      <td>244.162415</td>\n",
       "      <td>-6.320831</td>\n",
       "      <td>28.311933</td>\n",
       "      <td>-11.891333</td>\n",
       "      <td>95.821173</td>\n",
       "      <td>1.108855</td>\n",
       "      <td>0.007911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id02542</th>\n",
       "      <td>-2.104947</td>\n",
       "      <td>321.684747</td>\n",
       "      <td>-4.849337</td>\n",
       "      <td>12.144909</td>\n",
       "      <td>-15.626547</td>\n",
       "      <td>100.231684</td>\n",
       "      <td>1.114204</td>\n",
       "      <td>0.007847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id03178</th>\n",
       "      <td>7.786317</td>\n",
       "      <td>282.144113</td>\n",
       "      <td>-3.075381</td>\n",
       "      <td>14.572132</td>\n",
       "      <td>-8.942457</td>\n",
       "      <td>89.394456</td>\n",
       "      <td>1.077445</td>\n",
       "      <td>0.001368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id02576</th>\n",
       "      <td>3.747069</td>\n",
       "      <td>291.241495</td>\n",
       "      <td>-5.515895</td>\n",
       "      <td>35.456028</td>\n",
       "      <td>-12.475809</td>\n",
       "      <td>110.274470</td>\n",
       "      <td>1.137299</td>\n",
       "      <td>0.025376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00061</th>\n",
       "      <td>3.238690</td>\n",
       "      <td>264.379306</td>\n",
       "      <td>-5.900295</td>\n",
       "      <td>42.085206</td>\n",
       "      <td>-12.920921</td>\n",
       "      <td>90.969798</td>\n",
       "      <td>1.088251</td>\n",
       "      <td>0.010301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id02685</th>\n",
       "      <td>1.697447</td>\n",
       "      <td>295.381371</td>\n",
       "      <td>-7.632659</td>\n",
       "      <td>74.722317</td>\n",
       "      <td>-15.366300</td>\n",
       "      <td>154.420272</td>\n",
       "      <td>1.121202</td>\n",
       "      <td>0.007587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01437</th>\n",
       "      <td>1.622638</td>\n",
       "      <td>242.125099</td>\n",
       "      <td>-7.557509</td>\n",
       "      <td>28.103867</td>\n",
       "      <td>-14.776479</td>\n",
       "      <td>91.489681</td>\n",
       "      <td>1.169886</td>\n",
       "      <td>0.060630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id02317</th>\n",
       "      <td>6.839317</td>\n",
       "      <td>298.071964</td>\n",
       "      <td>-4.488185</td>\n",
       "      <td>14.667382</td>\n",
       "      <td>-10.478240</td>\n",
       "      <td>92.941960</td>\n",
       "      <td>1.092339</td>\n",
       "      <td>0.003122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01541</th>\n",
       "      <td>2.235133</td>\n",
       "      <td>298.458492</td>\n",
       "      <td>-4.269624</td>\n",
       "      <td>21.423694</td>\n",
       "      <td>-12.506852</td>\n",
       "      <td>95.011260</td>\n",
       "      <td>1.085901</td>\n",
       "      <td>0.001575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id02725</th>\n",
       "      <td>3.903177</td>\n",
       "      <td>351.447215</td>\n",
       "      <td>-4.756758</td>\n",
       "      <td>54.680669</td>\n",
       "      <td>-12.307530</td>\n",
       "      <td>161.596581</td>\n",
       "      <td>1.102463</td>\n",
       "      <td>0.004791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id03347</th>\n",
       "      <td>4.419074</td>\n",
       "      <td>323.070521</td>\n",
       "      <td>-4.540062</td>\n",
       "      <td>26.155481</td>\n",
       "      <td>-11.665580</td>\n",
       "      <td>122.489873</td>\n",
       "      <td>1.112678</td>\n",
       "      <td>0.004434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00081</th>\n",
       "      <td>-2.780090</td>\n",
       "      <td>240.749590</td>\n",
       "      <td>-5.653435</td>\n",
       "      <td>26.975984</td>\n",
       "      <td>-15.623087</td>\n",
       "      <td>71.986695</td>\n",
       "      <td>1.088496</td>\n",
       "      <td>0.021552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id03041</th>\n",
       "      <td>5.171804</td>\n",
       "      <td>279.228688</td>\n",
       "      <td>-5.316593</td>\n",
       "      <td>45.364751</td>\n",
       "      <td>-11.870606</td>\n",
       "      <td>98.989794</td>\n",
       "      <td>1.077725</td>\n",
       "      <td>0.003805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00812</th>\n",
       "      <td>11.350175</td>\n",
       "      <td>276.657216</td>\n",
       "      <td>-3.602522</td>\n",
       "      <td>73.304162</td>\n",
       "      <td>-7.854904</td>\n",
       "      <td>147.623598</td>\n",
       "      <td>1.106002</td>\n",
       "      <td>0.013364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id02745</th>\n",
       "      <td>-3.312683</td>\n",
       "      <td>292.570633</td>\n",
       "      <td>-4.175924</td>\n",
       "      <td>28.609280</td>\n",
       "      <td>-15.474520</td>\n",
       "      <td>93.093842</td>\n",
       "      <td>1.073452</td>\n",
       "      <td>0.005466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id02445</th>\n",
       "      <td>13.336598</td>\n",
       "      <td>214.088147</td>\n",
       "      <td>-4.135340</td>\n",
       "      <td>89.675115</td>\n",
       "      <td>-6.662871</td>\n",
       "      <td>151.657560</td>\n",
       "      <td>1.205247</td>\n",
       "      <td>0.067867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id02286</th>\n",
       "      <td>10.466666</td>\n",
       "      <td>286.827800</td>\n",
       "      <td>-2.265988</td>\n",
       "      <td>36.679504</td>\n",
       "      <td>-7.083275</td>\n",
       "      <td>124.360270</td>\n",
       "      <td>1.100064</td>\n",
       "      <td>0.003822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01228</th>\n",
       "      <td>13.342182</td>\n",
       "      <td>305.823892</td>\n",
       "      <td>-2.335665</td>\n",
       "      <td>63.116245</td>\n",
       "      <td>-6.311874</td>\n",
       "      <td>162.611560</td>\n",
       "      <td>1.149991</td>\n",
       "      <td>0.015557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00562</th>\n",
       "      <td>4.285005</td>\n",
       "      <td>327.668711</td>\n",
       "      <td>-4.799128</td>\n",
       "      <td>47.606219</td>\n",
       "      <td>-12.106152</td>\n",
       "      <td>135.562725</td>\n",
       "      <td>1.234401</td>\n",
       "      <td>0.305864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00817</th>\n",
       "      <td>8.677057</td>\n",
       "      <td>349.792143</td>\n",
       "      <td>-2.561542</td>\n",
       "      <td>26.647149</td>\n",
       "      <td>-8.802467</td>\n",
       "      <td>134.523906</td>\n",
       "      <td>1.098018</td>\n",
       "      <td>0.003653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01298</th>\n",
       "      <td>-8.228609</td>\n",
       "      <td>144.865380</td>\n",
       "      <td>-7.920028</td>\n",
       "      <td>24.649797</td>\n",
       "      <td>-20.106512</td>\n",
       "      <td>34.786699</td>\n",
       "      <td>1.044979</td>\n",
       "      <td>0.000594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01106</th>\n",
       "      <td>-3.194769</td>\n",
       "      <td>288.899605</td>\n",
       "      <td>-4.754414</td>\n",
       "      <td>22.897937</td>\n",
       "      <td>-15.854935</td>\n",
       "      <td>89.989095</td>\n",
       "      <td>1.082707</td>\n",
       "      <td>0.012435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id02181</th>\n",
       "      <td>5.601613</td>\n",
       "      <td>240.037613</td>\n",
       "      <td>-8.024551</td>\n",
       "      <td>64.705607</td>\n",
       "      <td>-13.122138</td>\n",
       "      <td>123.102031</td>\n",
       "      <td>1.081857</td>\n",
       "      <td>0.007474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00926</th>\n",
       "      <td>3.935958</td>\n",
       "      <td>344.245323</td>\n",
       "      <td>-3.868774</td>\n",
       "      <td>32.722609</td>\n",
       "      <td>-11.832631</td>\n",
       "      <td>120.366396</td>\n",
       "      <td>1.186346</td>\n",
       "      <td>0.070054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id02057</th>\n",
       "      <td>1.399163</td>\n",
       "      <td>268.751767</td>\n",
       "      <td>-7.240883</td>\n",
       "      <td>40.515187</td>\n",
       "      <td>-14.772159</td>\n",
       "      <td>118.598792</td>\n",
       "      <td>1.088567</td>\n",
       "      <td>0.005491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00017</th>\n",
       "      <td>7.713406</td>\n",
       "      <td>247.168665</td>\n",
       "      <td>-4.620244</td>\n",
       "      <td>36.645736</td>\n",
       "      <td>-9.606020</td>\n",
       "      <td>86.449585</td>\n",
       "      <td>1.065860</td>\n",
       "      <td>0.001258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id02548</th>\n",
       "      <td>4.295708</td>\n",
       "      <td>341.755795</td>\n",
       "      <td>-4.459155</td>\n",
       "      <td>59.032867</td>\n",
       "      <td>-11.750260</td>\n",
       "      <td>162.620530</td>\n",
       "      <td>1.107627</td>\n",
       "      <td>0.012931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01567</th>\n",
       "      <td>3.847641</td>\n",
       "      <td>310.728624</td>\n",
       "      <td>-4.268416</td>\n",
       "      <td>49.613809</td>\n",
       "      <td>-11.537179</td>\n",
       "      <td>134.659116</td>\n",
       "      <td>1.152881</td>\n",
       "      <td>0.034293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id03524</th>\n",
       "      <td>0.884167</td>\n",
       "      <td>294.991334</td>\n",
       "      <td>-5.819931</td>\n",
       "      <td>28.384963</td>\n",
       "      <td>-14.241296</td>\n",
       "      <td>106.158957</td>\n",
       "      <td>1.106322</td>\n",
       "      <td>0.020820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01224</th>\n",
       "      <td>3.619571</td>\n",
       "      <td>261.505959</td>\n",
       "      <td>-6.668529</td>\n",
       "      <td>62.524474</td>\n",
       "      <td>-13.105795</td>\n",
       "      <td>130.228975</td>\n",
       "      <td>1.075575</td>\n",
       "      <td>0.001558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01000</th>\n",
       "      <td>4.116924</td>\n",
       "      <td>247.172561</td>\n",
       "      <td>-7.664732</td>\n",
       "      <td>63.943536</td>\n",
       "      <td>-13.554640</td>\n",
       "      <td>125.575474</td>\n",
       "      <td>1.102622</td>\n",
       "      <td>0.007714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id03382</th>\n",
       "      <td>14.124792</td>\n",
       "      <td>228.240307</td>\n",
       "      <td>-3.304357</td>\n",
       "      <td>59.620963</td>\n",
       "      <td>-6.210030</td>\n",
       "      <td>133.529021</td>\n",
       "      <td>1.087554</td>\n",
       "      <td>0.003888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01989</th>\n",
       "      <td>-0.190612</td>\n",
       "      <td>262.695044</td>\n",
       "      <td>-6.532930</td>\n",
       "      <td>18.403831</td>\n",
       "      <td>-15.284541</td>\n",
       "      <td>74.177678</td>\n",
       "      <td>1.107863</td>\n",
       "      <td>0.023947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id02465</th>\n",
       "      <td>13.588449</td>\n",
       "      <td>216.248073</td>\n",
       "      <td>-5.012906</td>\n",
       "      <td>73.518351</td>\n",
       "      <td>-7.619992</td>\n",
       "      <td>138.391161</td>\n",
       "      <td>1.128489</td>\n",
       "      <td>0.035890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01460</th>\n",
       "      <td>2.019303</td>\n",
       "      <td>379.310090</td>\n",
       "      <td>-3.462100</td>\n",
       "      <td>49.089900</td>\n",
       "      <td>-12.524771</td>\n",
       "      <td>168.308020</td>\n",
       "      <td>1.114616</td>\n",
       "      <td>0.016529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id03127</th>\n",
       "      <td>5.715594</td>\n",
       "      <td>317.035401</td>\n",
       "      <td>-4.116052</td>\n",
       "      <td>36.654706</td>\n",
       "      <td>-10.828829</td>\n",
       "      <td>121.958398</td>\n",
       "      <td>1.099110</td>\n",
       "      <td>0.005250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01618</th>\n",
       "      <td>11.162688</td>\n",
       "      <td>278.431808</td>\n",
       "      <td>-3.875685</td>\n",
       "      <td>78.092576</td>\n",
       "      <td>-7.917177</td>\n",
       "      <td>159.099237</td>\n",
       "      <td>1.098252</td>\n",
       "      <td>0.006612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id03030</th>\n",
       "      <td>10.266477</td>\n",
       "      <td>263.064625</td>\n",
       "      <td>-3.824514</td>\n",
       "      <td>40.086290</td>\n",
       "      <td>-8.421124</td>\n",
       "      <td>107.326767</td>\n",
       "      <td>1.080680</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01041</th>\n",
       "      <td>4.149202</td>\n",
       "      <td>275.542377</td>\n",
       "      <td>-6.063803</td>\n",
       "      <td>51.181981</td>\n",
       "      <td>-12.567392</td>\n",
       "      <td>124.636939</td>\n",
       "      <td>1.181876</td>\n",
       "      <td>0.039112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id02086</th>\n",
       "      <td>6.291865</td>\n",
       "      <td>285.621915</td>\n",
       "      <td>-7.362467</td>\n",
       "      <td>80.265437</td>\n",
       "      <td>-12.545916</td>\n",
       "      <td>165.051639</td>\n",
       "      <td>1.082809</td>\n",
       "      <td>0.003114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01333</th>\n",
       "      <td>12.881032</td>\n",
       "      <td>246.284485</td>\n",
       "      <td>-5.460095</td>\n",
       "      <td>92.117183</td>\n",
       "      <td>-8.376378</td>\n",
       "      <td>162.991751</td>\n",
       "      <td>1.125861</td>\n",
       "      <td>0.007226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01509</th>\n",
       "      <td>5.114587</td>\n",
       "      <td>323.164807</td>\n",
       "      <td>-5.906193</td>\n",
       "      <td>57.623192</td>\n",
       "      <td>-12.551856</td>\n",
       "      <td>149.463566</td>\n",
       "      <td>1.090427</td>\n",
       "      <td>0.005716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01822</th>\n",
       "      <td>1.159351</td>\n",
       "      <td>303.187762</td>\n",
       "      <td>-5.539486</td>\n",
       "      <td>27.575569</td>\n",
       "      <td>-14.095322</td>\n",
       "      <td>93.493667</td>\n",
       "      <td>1.076440</td>\n",
       "      <td>0.001679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SIR_MEAN  SIR_VARIANCE  SAR_MEAN  SAR_VARIANCE   SDR_MEAN  \\\n",
       "Key                                                                   \n",
       "id00154  10.521380    227.802958 -4.142282     18.451845  -8.231168   \n",
       "id00866   6.617601    343.371110 -3.835985     26.908087 -10.557370   \n",
       "id01066   8.324409    319.070619 -3.091958     26.173350  -8.877471   \n",
       "id00419   0.870727    330.560557 -5.923366     48.326800 -14.635148   \n",
       "id01892  -1.816690    254.610565 -8.194641     59.926393 -17.643697   \n",
       "id02577   0.987114    287.076045 -5.062195     42.158743 -13.372956   \n",
       "id02019   0.602653    278.713769 -5.613182     22.466980 -13.967106   \n",
       "id01593   5.811400    244.162415 -6.320831     28.311933 -11.891333   \n",
       "id02542  -2.104947    321.684747 -4.849337     12.144909 -15.626547   \n",
       "id03178   7.786317    282.144113 -3.075381     14.572132  -8.942457   \n",
       "id02576   3.747069    291.241495 -5.515895     35.456028 -12.475809   \n",
       "id00061   3.238690    264.379306 -5.900295     42.085206 -12.920921   \n",
       "id02685   1.697447    295.381371 -7.632659     74.722317 -15.366300   \n",
       "id01437   1.622638    242.125099 -7.557509     28.103867 -14.776479   \n",
       "id02317   6.839317    298.071964 -4.488185     14.667382 -10.478240   \n",
       "id01541   2.235133    298.458492 -4.269624     21.423694 -12.506852   \n",
       "id02725   3.903177    351.447215 -4.756758     54.680669 -12.307530   \n",
       "id03347   4.419074    323.070521 -4.540062     26.155481 -11.665580   \n",
       "id00081  -2.780090    240.749590 -5.653435     26.975984 -15.623087   \n",
       "id03041   5.171804    279.228688 -5.316593     45.364751 -11.870606   \n",
       "id00812  11.350175    276.657216 -3.602522     73.304162  -7.854904   \n",
       "id02745  -3.312683    292.570633 -4.175924     28.609280 -15.474520   \n",
       "id02445  13.336598    214.088147 -4.135340     89.675115  -6.662871   \n",
       "id02286  10.466666    286.827800 -2.265988     36.679504  -7.083275   \n",
       "id01228  13.342182    305.823892 -2.335665     63.116245  -6.311874   \n",
       "id00562   4.285005    327.668711 -4.799128     47.606219 -12.106152   \n",
       "id00817   8.677057    349.792143 -2.561542     26.647149  -8.802467   \n",
       "id01298  -8.228609    144.865380 -7.920028     24.649797 -20.106512   \n",
       "id01106  -3.194769    288.899605 -4.754414     22.897937 -15.854935   \n",
       "id02181   5.601613    240.037613 -8.024551     64.705607 -13.122138   \n",
       "id00926   3.935958    344.245323 -3.868774     32.722609 -11.832631   \n",
       "id02057   1.399163    268.751767 -7.240883     40.515187 -14.772159   \n",
       "id00017   7.713406    247.168665 -4.620244     36.645736  -9.606020   \n",
       "id02548   4.295708    341.755795 -4.459155     59.032867 -11.750260   \n",
       "id01567   3.847641    310.728624 -4.268416     49.613809 -11.537179   \n",
       "id03524   0.884167    294.991334 -5.819931     28.384963 -14.241296   \n",
       "id01224   3.619571    261.505959 -6.668529     62.524474 -13.105795   \n",
       "id01000   4.116924    247.172561 -7.664732     63.943536 -13.554640   \n",
       "id03382  14.124792    228.240307 -3.304357     59.620963  -6.210030   \n",
       "id01989  -0.190612    262.695044 -6.532930     18.403831 -15.284541   \n",
       "id02465  13.588449    216.248073 -5.012906     73.518351  -7.619992   \n",
       "id01460   2.019303    379.310090 -3.462100     49.089900 -12.524771   \n",
       "id03127   5.715594    317.035401 -4.116052     36.654706 -10.828829   \n",
       "id01618  11.162688    278.431808 -3.875685     78.092576  -7.917177   \n",
       "id03030  10.266477    263.064625 -3.824514     40.086290  -8.421124   \n",
       "id01041   4.149202    275.542377 -6.063803     51.181981 -12.567392   \n",
       "id02086   6.291865    285.621915 -7.362467     80.265437 -12.545916   \n",
       "id01333  12.881032    246.284485 -5.460095     92.117183  -8.376378   \n",
       "id01509   5.114587    323.164807 -5.906193     57.623192 -12.551856   \n",
       "id01822   1.159351    303.187762 -5.539486     27.575569 -14.095322   \n",
       "\n",
       "         SDR_VARIANCE  PESQ_MEAN  PESQ_VARIANCE  \n",
       "Key                                              \n",
       "id00154     81.194939   1.110132       0.004038  \n",
       "id00866    118.509879   1.121674       0.040492  \n",
       "id01066    108.790636   1.117321       0.008584  \n",
       "id00419    157.250794   1.071582       0.002424  \n",
       "id01892     88.353395   1.079743       0.008471  \n",
       "id02577    122.273652   1.122451       0.011619  \n",
       "id02019    124.655204   1.079537       0.003499  \n",
       "id01593     95.821173   1.108855       0.007911  \n",
       "id02542    100.231684   1.114204       0.007847  \n",
       "id03178     89.394456   1.077445       0.001368  \n",
       "id02576    110.274470   1.137299       0.025376  \n",
       "id00061     90.969798   1.088251       0.010301  \n",
       "id02685    154.420272   1.121202       0.007587  \n",
       "id01437     91.489681   1.169886       0.060630  \n",
       "id02317     92.941960   1.092339       0.003122  \n",
       "id01541     95.011260   1.085901       0.001575  \n",
       "id02725    161.596581   1.102463       0.004791  \n",
       "id03347    122.489873   1.112678       0.004434  \n",
       "id00081     71.986695   1.088496       0.021552  \n",
       "id03041     98.989794   1.077725       0.003805  \n",
       "id00812    147.623598   1.106002       0.013364  \n",
       "id02745     93.093842   1.073452       0.005466  \n",
       "id02445    151.657560   1.205247       0.067867  \n",
       "id02286    124.360270   1.100064       0.003822  \n",
       "id01228    162.611560   1.149991       0.015557  \n",
       "id00562    135.562725   1.234401       0.305864  \n",
       "id00817    134.523906   1.098018       0.003653  \n",
       "id01298     34.786699   1.044979       0.000594  \n",
       "id01106     89.989095   1.082707       0.012435  \n",
       "id02181    123.102031   1.081857       0.007474  \n",
       "id00926    120.366396   1.186346       0.070054  \n",
       "id02057    118.598792   1.088567       0.005491  \n",
       "id00017     86.449585   1.065860       0.001258  \n",
       "id02548    162.620530   1.107627       0.012931  \n",
       "id01567    134.659116   1.152881       0.034293  \n",
       "id03524    106.158957   1.106322       0.020820  \n",
       "id01224    130.228975   1.075575       0.001558  \n",
       "id01000    125.575474   1.102622       0.007714  \n",
       "id03382    133.529021   1.087554       0.003888  \n",
       "id01989     74.177678   1.107863       0.023947  \n",
       "id02465    138.391161   1.128489       0.035890  \n",
       "id01460    168.308020   1.114616       0.016529  \n",
       "id03127    121.958398   1.099110       0.005250  \n",
       "id01618    159.099237   1.098252       0.006612  \n",
       "id03030    107.326767   1.080680       0.002347  \n",
       "id01041    124.636939   1.181876       0.039112  \n",
       "id02086    165.051639   1.082809       0.003114  \n",
       "id01333    162.991751   1.125861       0.007226  \n",
       "id01509    149.463566   1.090427       0.005716  \n",
       "id01822     93.493667   1.076440       0.001679  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, use the above pre-trained and finetuned speaker identification model (obtained in II) to identify which enhanced speech corresponds to which speaker after speaker separation. Report the Rank-1 identification accuracy on both models. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lora_finetune import *\n",
    "from evaluation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/raid/.cache/torch/hub/s3prl_s3prl_main\n",
      "WARNING:s3prl.upstream.espnet_hubert.expert:ESPnet is not installed, cannot use espnet_hubert upstream\n",
      "INFO:s3prl.util.download:Requesting URL: https://huggingface.co/s3prl/converted_ckpts/resolve/main/wavlm_base_plus.pt\n",
      "INFO:s3prl.util.download:Using URL's local file: /home/raid/.cache/s3prl/download/72cb34edf8a3724c720467cf40b77ad20b1b714b5f694e9db57f521467f9006b.wavlm_base_plus.pt\n",
      "INFO:s3prl.upstream.wavlm.WavLM:WavLM Config: {'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 0.1, 'normalize': False, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'dropout_features': 0.1, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}\n"
     ]
    }
   ],
   "source": [
    "model = init_model('models/checkpoints/wavlm_base_plus_nofinetune.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECAPA_TDNN(\n",
       "  (feature_extract): UpstreamExpert(\n",
       "    (model): WavLM(\n",
       "      (feature_extractor): ConvFeatureExtractionModel(\n",
       "        (conv_layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "            (3): GELU(approximate='none')\n",
       "          )\n",
       "          (1-4): 4 x Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): GELU(approximate='none')\n",
       "          )\n",
       "          (5-6): 2 x Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): GELU(approximate='none')\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)\n",
       "      (dropout_input): Dropout(p=0.1, inplace=False)\n",
       "      (dropout_features): Dropout(p=0.1, inplace=False)\n",
       "      (encoder): TransformerEncoder(\n",
       "        (pos_conv): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "          (1): SamePad()\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): Dropout(p=0.1, inplace=False)\n",
       "              (relative_attention_bias): Embedding(320, 12)\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1-11): 11 x TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): Dropout(p=0.1, inplace=False)\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (instance_norm): InstanceNorm1d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (layer1): Conv1dReluBn(\n",
       "    (conv): Conv1d(768, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (layer2): SE_Res2Block(\n",
       "    (Conv1dReluBn1): Conv1dReluBn(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Res2Conv1dReluBn): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0-6): 7 x Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0-6): 7 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Conv1dReluBn2): Conv1dReluBn(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (SE_Connect): SE_Connect(\n",
       "      (linear1): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (linear2): Linear(in_features=128, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): SE_Res2Block(\n",
       "    (Conv1dReluBn1): Conv1dReluBn(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Res2Conv1dReluBn): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0-6): 7 x Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0-6): 7 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Conv1dReluBn2): Conv1dReluBn(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (SE_Connect): SE_Connect(\n",
       "      (linear1): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (linear2): Linear(in_features=128, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): SE_Res2Block(\n",
       "    (Conv1dReluBn1): Conv1dReluBn(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Res2Conv1dReluBn): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0-6): 7 x Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0-6): 7 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Conv1dReluBn2): Conv1dReluBn(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (SE_Connect): SE_Connect(\n",
       "      (linear1): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (linear2): Linear(in_features=128, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (conv): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))\n",
       "  (pooling): AttentiveStatsPool(\n",
       "    (linear1): Conv1d(1536, 128, kernel_size=(1,), stride=(1,))\n",
       "    (linear2): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=3072, out_features=256, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 325.56it/s]\n"
     ]
    }
   ],
   "source": [
    "speaker_dict = {}\n",
    "for i in tqdm(range(len(vox_mix))):\n",
    "    _, wav_1, wav_2, sp1, sp2, _ = vox_mix[i]\n",
    "    \n",
    "    if sp1 not in speaker_dict.keys():\n",
    "        speaker_dict[sp1] = wav_1\n",
    "\n",
    "    if sp2 not in speaker_dict.keys():\n",
    "        speaker_dict[sp2] = wav_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id00812', 'id01618', 'id01822', 'id00061', 'id03524', 'id01567', 'id02181', 'id00419', 'id01892', 'id00866', 'id02577', 'id02542', 'id02086', 'id01460', 'id02445', 'id01041', 'id00081', 'id01298', 'id00926', 'id02317', 'id00154', 'id01333', 'id02745', 'id02548', 'id01106', 'id00562', 'id02725', 'id03127', 'id02019', 'id02685', 'id01224', 'id01000', 'id01437', 'id01593', 'id00017', 'id01989', 'id03382', 'id03178', 'id02057', 'id02576', 'id02286', 'id03030', 'id00817', 'id01509', 'id02465', 'id03347', 'id01541', 'id03041', 'id01066', 'id01228'])\n"
     ]
    }
   ],
   "source": [
    "print(speaker_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_list = list(speaker_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_matrix = torch.zeros((len(speaker_dict), 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_id = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.9165e-02, 1.9135e-02, 1.7029e-02,  ..., 6.1035e-05, 6.1035e-05,\n",
      "         6.1035e-05],\n",
      "        [1.9165e-02, 1.9135e-02, 1.7029e-02,  ..., 6.1035e-05, 6.1035e-05,\n",
      "         6.1035e-05]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0110, -0.0226, -0.0211,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0110, -0.0226, -0.0211,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 0.0388,  0.0301, -0.0053,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0388,  0.0301, -0.0053,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-6.4026e-02, -9.6375e-02, -1.1667e-01,  ...,  3.0518e-05,\n",
      "         -2.1362e-04,  6.4087e-04],\n",
      "        [-6.4026e-02, -9.6375e-02, -1.1667e-01,  ...,  3.0518e-05,\n",
      "         -2.1362e-04,  6.4087e-04]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-6.9214e-02, -7.7301e-02, -8.5449e-02,  ...,  9.1553e-05,\n",
      "         -1.5259e-04, -2.7466e-04],\n",
      "        [-6.9214e-02, -7.7301e-02, -8.5449e-02,  ...,  9.1553e-05,\n",
      "         -1.5259e-04, -2.7466e-04]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.1442, -0.1281, -0.0203,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.1442, -0.1281, -0.0203,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[0.0378, 0.0594, 0.0632,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0378, 0.0594, 0.0632,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 0.0026,  0.0021, -0.0003,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0026,  0.0021, -0.0003,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 0.0232, -0.0400, -0.1450,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0232, -0.0400, -0.1450,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0088, -0.0113, -0.0111,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0088, -0.0113, -0.0111,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0141, -0.0130, -0.0054,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0141, -0.0130, -0.0054,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 9.5825e-03,  6.6528e-03,  4.6082e-03,  ..., -9.1553e-05,\n",
      "         -1.5259e-04, -1.8311e-04],\n",
      "        [ 9.5825e-03,  6.6528e-03,  4.6082e-03,  ..., -9.1553e-05,\n",
      "         -1.5259e-04, -1.8311e-04]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0250, -0.0298,  0.0061,  ..., -0.0001, -0.0002,  0.0000],\n",
      "        [-0.0250, -0.0298,  0.0061,  ..., -0.0001, -0.0002,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[3.8727e-02, 4.7333e-02, 4.4647e-02,  ..., 1.2207e-04, 1.5259e-04,\n",
      "         3.0518e-05],\n",
      "        [3.8727e-02, 4.7333e-02, 4.4647e-02,  ..., 1.2207e-04, 1.5259e-04,\n",
      "         3.0518e-05]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 0.0045, -0.0054, -0.0102,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0045, -0.0054, -0.0102,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 2.1362e-04,  3.6621e-04,  4.2725e-04,  ..., -3.0518e-05,\n",
      "         -3.0518e-05,  0.0000e+00],\n",
      "        [ 2.1362e-04,  3.6621e-04,  4.2725e-04,  ..., -3.0518e-05,\n",
      "         -3.0518e-05,  0.0000e+00]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[0.0143, 0.0170, 0.0106,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0143, 0.0170, 0.0106,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0057,  0.0943,  0.2406,  ...,  0.0034,  0.0032,  0.0034],\n",
      "        [-0.0057,  0.0943,  0.2406,  ...,  0.0034,  0.0032,  0.0034]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[0.0117, 0.0182, 0.0201,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0117, 0.0182, 0.0201,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[0.0002, 0.0008, 0.0005,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0002, 0.0008, 0.0005,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 0.0009, -0.0101,  0.0003,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0009, -0.0101,  0.0003,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 0.0168,  0.0170,  0.0108,  ..., -0.0003, -0.0001, -0.0003],\n",
      "        [ 0.0168,  0.0170,  0.0108,  ..., -0.0003, -0.0001, -0.0003]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-9.9182e-03, -1.3153e-02, -5.2795e-03,  ...,  6.1035e-05,\n",
      "         -6.1035e-05,  0.0000e+00],\n",
      "        [-9.9182e-03, -1.3153e-02, -5.2795e-03,  ...,  6.1035e-05,\n",
      "         -6.1035e-05,  0.0000e+00]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 0.0291,  0.0114, -0.0002,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0291,  0.0114, -0.0002,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[2.4719e-03, 1.9836e-03, 2.4719e-03,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         3.0518e-05],\n",
      "        [2.4719e-03, 1.9836e-03, 2.4719e-03,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         3.0518e-05]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 0.0294,  0.0429,  0.0345,  ..., -0.0002, -0.0002, -0.0002],\n",
      "        [ 0.0294,  0.0429,  0.0345,  ..., -0.0002, -0.0002, -0.0002]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 3.7842e-03,  2.5452e-02,  7.1411e-03,  ...,  6.1035e-05,\n",
      "         -1.8311e-04, -2.4414e-04],\n",
      "        [ 3.7842e-03,  2.5452e-02,  7.1411e-03,  ...,  6.1035e-05,\n",
      "         -1.8311e-04, -2.4414e-04]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[0.0120, 0.0163, 0.0252,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0163, 0.0252,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 0.0140, -0.0295,  0.0904,  ..., -0.0002, -0.0003, -0.0001],\n",
      "        [ 0.0140, -0.0295,  0.0904,  ..., -0.0002, -0.0003, -0.0001]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[0.0053, 0.0056, 0.0021,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0053, 0.0056, 0.0021,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0064, -0.0057, -0.0025,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0064, -0.0057, -0.0025,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[0.0186, 0.0156, 0.0265,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0186, 0.0156, 0.0265,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0270, -0.0311, -0.0004,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0270, -0.0311, -0.0004,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-2.6337e-02, -2.8900e-02, -2.0447e-02,  ..., -6.1035e-05,\n",
      "          2.1362e-04,  2.7466e-04],\n",
      "        [-2.6337e-02, -2.8900e-02, -2.0447e-02,  ..., -6.1035e-05,\n",
      "          2.1362e-04,  2.7466e-04]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-3.2288e-02, -2.2461e-02, -3.3752e-02,  ...,  3.0518e-05,\n",
      "         -9.1553e-05, -2.1362e-04],\n",
      "        [-3.2288e-02, -2.2461e-02, -3.3752e-02,  ...,  3.0518e-05,\n",
      "         -9.1553e-05, -2.1362e-04]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 7.0190e-04,  1.3123e-03,  1.6785e-03,  ..., -3.0518e-05,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 7.0190e-04,  1.3123e-03,  1.6785e-03,  ..., -3.0518e-05,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 0.2328,  0.1283, -0.1161,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.2328,  0.1283, -0.1161,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 0.0026,  0.0026,  0.0018,  ...,  0.0006, -0.0002,  0.0001],\n",
      "        [ 0.0026,  0.0026,  0.0018,  ...,  0.0006, -0.0002,  0.0001]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0029, -0.0032, -0.0014,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0029, -0.0032, -0.0014,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0048, -0.0054, -0.0052,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0048, -0.0054, -0.0052,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0020, -0.0026, -0.0023,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0020, -0.0026, -0.0023,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0171, -0.0197, -0.0176,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0171, -0.0197, -0.0176,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 3.1708e-02,  3.4546e-02,  3.5706e-02,  ...,  3.0518e-05,\n",
      "         -3.0518e-05, -3.0518e-05],\n",
      "        [ 3.1708e-02,  3.4546e-02,  3.5706e-02,  ...,  3.0518e-05,\n",
      "         -3.0518e-05, -3.0518e-05]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[0.0069, 0.0085, 0.0052,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0069, 0.0085, 0.0052,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[0.0161, 0.0210, 0.0303,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0161, 0.0210, 0.0303,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0208, -0.0179, -0.0138,  ...,  0.0001,  0.0003,  0.0002],\n",
      "        [-0.0208, -0.0179, -0.0138,  ...,  0.0001,  0.0003,  0.0002]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[1.6083e-02, 2.1240e-02, 2.6367e-02,  ..., 6.1035e-05, 6.1035e-05,\n",
      "         9.1553e-05],\n",
      "        [1.6083e-02, 2.1240e-02, 2.6367e-02,  ..., 6.1035e-05, 6.1035e-05,\n",
      "         9.1553e-05]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-9.4604e-04,  1.2512e-03,  2.4719e-03,  ...,  6.1035e-05,\n",
      "          1.2207e-04, -6.1035e-05],\n",
      "        [-9.4604e-04,  1.2512e-03,  2.4719e-03,  ...,  6.1035e-05,\n",
      "          1.2207e-04, -6.1035e-05]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-1.2207e-04,  9.1553e-05, -1.5259e-04,  ..., -3.0518e-05,\n",
      "         -3.0518e-05, -6.1035e-05],\n",
      "        [-1.2207e-04,  9.1553e-05, -1.5259e-04,  ..., -3.0518e-05,\n",
      "         -3.0518e-05, -6.1035e-05]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0015, -0.0033, -0.0012,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0015, -0.0033, -0.0012,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n"
     ]
    }
   ],
   "source": [
    "for idx, kv in enumerate(speaker_dict.items()):\n",
    "    k, wav = kv\n",
    "    \n",
    "    wav = torch.stack([wav, wav], dim=0)\n",
    "    wav = wav.to(device)\n",
    "    wav = wav.squeeze_(1)\n",
    "    \n",
    "    print(wav)\n",
    "    embed = model(wav)[0, ...]\n",
    "    \n",
    "    print(embed[:10])\n",
    "    \n",
    "    print(\"!!!!!\")\n",
    "    embed_matrix[idx, :] = embed\n",
    "    \n",
    "    speaker_id[idx] = speaker_list.index(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0032,  0.0010,  0.0021,  ..., -0.0016, -0.0004, -0.0019],\n",
       "        [-0.0032,  0.0010,  0.0021,  ..., -0.0016, -0.0004, -0.0019],\n",
       "        [-0.0032,  0.0010,  0.0021,  ..., -0.0016, -0.0004, -0.0019],\n",
       "        ...,\n",
       "        [-0.0032,  0.0010,  0.0021,  ..., -0.0016, -0.0004, -0.0019],\n",
       "        [-0.0032,  0.0010,  0.0021,  ..., -0.0016, -0.0004, -0.0019],\n",
       "        [-0.0032,  0.0010,  0.0021,  ..., -0.0016, -0.0004, -0.0019]],\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "pred_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(n_samples)):\n",
    "    sample_idx = random.randint(0, len(vox_mix) - 1)\n",
    "    wav_mix, wav_s1, wav_s2, sp1, sp2, _ = vox_mix[sample_idx]\n",
    "    \n",
    "    min_sz = min(wav_s1.shape[-1], wav_s2.shape[-1])\n",
    "    \n",
    "    if wav_s1.shape[-1] > min_sz:\n",
    "        wav_s1 = wav_s1[:, :min_sz]\n",
    "    if wav_s2.shape[-1] > min_sz:\n",
    "        wav_s2 = wav_s2[:, :min_sz]\n",
    "\n",
    "    pred_s1, pred_s2 = speaker_separation(sepformer, wav_mix)\n",
    "\n",
    "    \n",
    "    gt = torch.cat([wav_s1, wav_s2], dim=0).numpy()\n",
    "    pred = torch.cat([pred_s1, pred_s2], dim=0).numpy()\n",
    "    \n",
    "    min_sz = min(gt.shape[-1], pred.shape[-1])\n",
    "    \n",
    "    if gt.shape[-1] > min_sz:\n",
    "        gt = gt[:, :min_sz]\n",
    "    if pred.shape[-1] > min_sz:\n",
    "        pred = pred[:, :min_sz]\n",
    "        \n",
    "    \n",
    "    embeds = model(pred)\n",
    "    \n",
    "    cos_sim = F.cosine_similarity(embeds, embed_matrix, dim=1)\n",
    "    \n",
    "    cos_sim = cos_sim.cpu().numpy()\n",
    "    \n",
    "    idx = cos_sim.argmax()\n",
    "    \n",
    "    labels.append(speaker_id[idx])\n",
    "    pred_labels.append(sp1)\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7204\n"
     ]
    }
   ],
   "source": [
    "print(acc(model, [labels, pred_labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_linear_with_lora(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['feature_weight', 'feature_extract.model.mask_emb', 'feature_extract.model.feature_extractor.conv_layers.0.0.weight', 'feature_extract.model.feature_extractor.conv_layers.0.2.weight', 'feature_extract.model.feature_extractor.conv_layers.0.2.bias', 'feature_extract.model.feature_extractor.conv_layers.1.0.weight', 'feature_extract.model.feature_extractor.conv_layers.2.0.weight', 'feature_extract.model.feature_extractor.conv_layers.3.0.weight', 'feature_extract.model.feature_extractor.conv_layers.4.0.weight', 'feature_extract.model.feature_extractor.conv_layers.5.0.weight', 'feature_extract.model.feature_extractor.conv_layers.6.0.weight', 'feature_extract.model.post_extract_proj.weight', 'feature_extract.model.post_extract_proj.bias', 'feature_extract.model.encoder.pos_conv.0.bias', 'feature_extract.model.encoder.pos_conv.0.weight_g', 'feature_extract.model.encoder.pos_conv.0.weight_v', 'feature_extract.model.encoder.layers.0.self_attn.grep_a', 'feature_extract.model.encoder.layers.0.self_attn.relative_attention_bias.weight', 'feature_extract.model.encoder.layers.0.self_attn.k_proj.weight', 'feature_extract.model.encoder.layers.0.self_attn.k_proj.bias', 'feature_extract.model.encoder.layers.0.self_attn.v_proj.weight', 'feature_extract.model.encoder.layers.0.self_attn.v_proj.bias', 'feature_extract.model.encoder.layers.0.self_attn.q_proj.weight', 'feature_extract.model.encoder.layers.0.self_attn.q_proj.bias', 'feature_extract.model.encoder.layers.0.self_attn.out_proj.weight', 'feature_extract.model.encoder.layers.0.self_attn.out_proj.bias', 'feature_extract.model.encoder.layers.0.self_attn.grep_linear.weight', 'feature_extract.model.encoder.layers.0.self_attn.grep_linear.bias', 'feature_extract.model.encoder.layers.0.self_attn_layer_norm.weight', 'feature_extract.model.encoder.layers.0.self_attn_layer_norm.bias', 'feature_extract.model.encoder.layers.0.fc1.weight', 'feature_extract.model.encoder.layers.0.fc1.bias', 'feature_extract.model.encoder.layers.0.fc2.weight', 'feature_extract.model.encoder.layers.0.fc2.bias', 'feature_extract.model.encoder.layers.0.final_layer_norm.weight', 'feature_extract.model.encoder.layers.0.final_layer_norm.bias', 'feature_extract.model.encoder.layers.1.self_attn.grep_a', 'feature_extract.model.encoder.layers.1.self_attn.k_proj.weight', 'feature_extract.model.encoder.layers.1.self_attn.k_proj.bias', 'feature_extract.model.encoder.layers.1.self_attn.v_proj.weight', 'feature_extract.model.encoder.layers.1.self_attn.v_proj.bias', 'feature_extract.model.encoder.layers.1.self_attn.q_proj.weight', 'feature_extract.model.encoder.layers.1.self_attn.q_proj.bias', 'feature_extract.model.encoder.layers.1.self_attn.out_proj.weight', 'feature_extract.model.encoder.layers.1.self_attn.out_proj.bias', 'feature_extract.model.encoder.layers.1.self_attn.grep_linear.weight', 'feature_extract.model.encoder.layers.1.self_attn.grep_linear.bias', 'feature_extract.model.encoder.layers.1.self_attn_layer_norm.weight', 'feature_extract.model.encoder.layers.1.self_attn_layer_norm.bias', 'feature_extract.model.encoder.layers.1.fc1.weight', 'feature_extract.model.encoder.layers.1.fc1.bias', 'feature_extract.model.encoder.layers.1.fc2.weight', 'feature_extract.model.encoder.layers.1.fc2.bias', 'feature_extract.model.encoder.layers.1.final_layer_norm.weight', 'feature_extract.model.encoder.layers.1.final_layer_norm.bias', 'feature_extract.model.encoder.layers.2.self_attn.grep_a', 'feature_extract.model.encoder.layers.2.self_attn.k_proj.weight', 'feature_extract.model.encoder.layers.2.self_attn.k_proj.bias', 'feature_extract.model.encoder.layers.2.self_attn.v_proj.weight', 'feature_extract.model.encoder.layers.2.self_attn.v_proj.bias', 'feature_extract.model.encoder.layers.2.self_attn.q_proj.weight', 'feature_extract.model.encoder.layers.2.self_attn.q_proj.bias', 'feature_extract.model.encoder.layers.2.self_attn.out_proj.weight', 'feature_extract.model.encoder.layers.2.self_attn.out_proj.bias', 'feature_extract.model.encoder.layers.2.self_attn.grep_linear.weight', 'feature_extract.model.encoder.layers.2.self_attn.grep_linear.bias', 'feature_extract.model.encoder.layers.2.self_attn_layer_norm.weight', 'feature_extract.model.encoder.layers.2.self_attn_layer_norm.bias', 'feature_extract.model.encoder.layers.2.fc1.weight', 'feature_extract.model.encoder.layers.2.fc1.bias', 'feature_extract.model.encoder.layers.2.fc2.weight', 'feature_extract.model.encoder.layers.2.fc2.bias', 'feature_extract.model.encoder.layers.2.final_layer_norm.weight', 'feature_extract.model.encoder.layers.2.final_layer_norm.bias', 'feature_extract.model.encoder.layers.3.self_attn.grep_a', 'feature_extract.model.encoder.layers.3.self_attn.k_proj.weight', 'feature_extract.model.encoder.layers.3.self_attn.k_proj.bias', 'feature_extract.model.encoder.layers.3.self_attn.v_proj.weight', 'feature_extract.model.encoder.layers.3.self_attn.v_proj.bias', 'feature_extract.model.encoder.layers.3.self_attn.q_proj.weight', 'feature_extract.model.encoder.layers.3.self_attn.q_proj.bias', 'feature_extract.model.encoder.layers.3.self_attn.out_proj.weight', 'feature_extract.model.encoder.layers.3.self_attn.out_proj.bias', 'feature_extract.model.encoder.layers.3.self_attn.grep_linear.weight', 'feature_extract.model.encoder.layers.3.self_attn.grep_linear.bias', 'feature_extract.model.encoder.layers.3.self_attn_layer_norm.weight', 'feature_extract.model.encoder.layers.3.self_attn_layer_norm.bias', 'feature_extract.model.encoder.layers.3.fc1.weight', 'feature_extract.model.encoder.layers.3.fc1.bias', 'feature_extract.model.encoder.layers.3.fc2.weight', 'feature_extract.model.encoder.layers.3.fc2.bias', 'feature_extract.model.encoder.layers.3.final_layer_norm.weight', 'feature_extract.model.encoder.layers.3.final_layer_norm.bias', 'feature_extract.model.encoder.layers.4.self_attn.grep_a', 'feature_extract.model.encoder.layers.4.self_attn.k_proj.weight', 'feature_extract.model.encoder.layers.4.self_attn.k_proj.bias', 'feature_extract.model.encoder.layers.4.self_attn.v_proj.weight', 'feature_extract.model.encoder.layers.4.self_attn.v_proj.bias', 'feature_extract.model.encoder.layers.4.self_attn.q_proj.weight', 'feature_extract.model.encoder.layers.4.self_attn.q_proj.bias', 'feature_extract.model.encoder.layers.4.self_attn.out_proj.weight', 'feature_extract.model.encoder.layers.4.self_attn.out_proj.bias', 'feature_extract.model.encoder.layers.4.self_attn.grep_linear.weight', 'feature_extract.model.encoder.layers.4.self_attn.grep_linear.bias', 'feature_extract.model.encoder.layers.4.self_attn_layer_norm.weight', 'feature_extract.model.encoder.layers.4.self_attn_layer_norm.bias', 'feature_extract.model.encoder.layers.4.fc1.weight', 'feature_extract.model.encoder.layers.4.fc1.bias', 'feature_extract.model.encoder.layers.4.fc2.weight', 'feature_extract.model.encoder.layers.4.fc2.bias', 'feature_extract.model.encoder.layers.4.final_layer_norm.weight', 'feature_extract.model.encoder.layers.4.final_layer_norm.bias', 'feature_extract.model.encoder.layers.5.self_attn.grep_a', 'feature_extract.model.encoder.layers.5.self_attn.k_proj.weight', 'feature_extract.model.encoder.layers.5.self_attn.k_proj.bias', 'feature_extract.model.encoder.layers.5.self_attn.v_proj.weight', 'feature_extract.model.encoder.layers.5.self_attn.v_proj.bias', 'feature_extract.model.encoder.layers.5.self_attn.q_proj.weight', 'feature_extract.model.encoder.layers.5.self_attn.q_proj.bias', 'feature_extract.model.encoder.layers.5.self_attn.out_proj.weight', 'feature_extract.model.encoder.layers.5.self_attn.out_proj.bias', 'feature_extract.model.encoder.layers.5.self_attn.grep_linear.weight', 'feature_extract.model.encoder.layers.5.self_attn.grep_linear.bias', 'feature_extract.model.encoder.layers.5.self_attn_layer_norm.weight', 'feature_extract.model.encoder.layers.5.self_attn_layer_norm.bias', 'feature_extract.model.encoder.layers.5.fc1.weight', 'feature_extract.model.encoder.layers.5.fc1.bias', 'feature_extract.model.encoder.layers.5.fc2.weight', 'feature_extract.model.encoder.layers.5.fc2.bias', 'feature_extract.model.encoder.layers.5.final_layer_norm.weight', 'feature_extract.model.encoder.layers.5.final_layer_norm.bias', 'feature_extract.model.encoder.layers.6.self_attn.grep_a', 'feature_extract.model.encoder.layers.6.self_attn.k_proj.weight', 'feature_extract.model.encoder.layers.6.self_attn.k_proj.bias', 'feature_extract.model.encoder.layers.6.self_attn.v_proj.weight', 'feature_extract.model.encoder.layers.6.self_attn.v_proj.bias', 'feature_extract.model.encoder.layers.6.self_attn.q_proj.weight', 'feature_extract.model.encoder.layers.6.self_attn.q_proj.bias', 'feature_extract.model.encoder.layers.6.self_attn.out_proj.weight', 'feature_extract.model.encoder.layers.6.self_attn.out_proj.bias', 'feature_extract.model.encoder.layers.6.self_attn.grep_linear.weight', 'feature_extract.model.encoder.layers.6.self_attn.grep_linear.bias', 'feature_extract.model.encoder.layers.6.self_attn_layer_norm.weight', 'feature_extract.model.encoder.layers.6.self_attn_layer_norm.bias', 'feature_extract.model.encoder.layers.6.fc1.weight', 'feature_extract.model.encoder.layers.6.fc1.bias', 'feature_extract.model.encoder.layers.6.fc2.weight', 'feature_extract.model.encoder.layers.6.fc2.bias', 'feature_extract.model.encoder.layers.6.final_layer_norm.weight', 'feature_extract.model.encoder.layers.6.final_layer_norm.bias', 'feature_extract.model.encoder.layers.7.self_attn.grep_a', 'feature_extract.model.encoder.layers.7.self_attn.k_proj.weight', 'feature_extract.model.encoder.layers.7.self_attn.k_proj.bias', 'feature_extract.model.encoder.layers.7.self_attn.v_proj.weight', 'feature_extract.model.encoder.layers.7.self_attn.v_proj.bias', 'feature_extract.model.encoder.layers.7.self_attn.q_proj.weight', 'feature_extract.model.encoder.layers.7.self_attn.q_proj.bias', 'feature_extract.model.encoder.layers.7.self_attn.out_proj.weight', 'feature_extract.model.encoder.layers.7.self_attn.out_proj.bias', 'feature_extract.model.encoder.layers.7.self_attn.grep_linear.weight', 'feature_extract.model.encoder.layers.7.self_attn.grep_linear.bias', 'feature_extract.model.encoder.layers.7.self_attn_layer_norm.weight', 'feature_extract.model.encoder.layers.7.self_attn_layer_norm.bias', 'feature_extract.model.encoder.layers.7.fc1.weight', 'feature_extract.model.encoder.layers.7.fc1.bias', 'feature_extract.model.encoder.layers.7.fc2.weight', 'feature_extract.model.encoder.layers.7.fc2.bias', 'feature_extract.model.encoder.layers.7.final_layer_norm.weight', 'feature_extract.model.encoder.layers.7.final_layer_norm.bias', 'feature_extract.model.encoder.layers.8.self_attn.grep_a', 'feature_extract.model.encoder.layers.8.self_attn.k_proj.weight', 'feature_extract.model.encoder.layers.8.self_attn.k_proj.bias', 'feature_extract.model.encoder.layers.8.self_attn.v_proj.weight', 'feature_extract.model.encoder.layers.8.self_attn.v_proj.bias', 'feature_extract.model.encoder.layers.8.self_attn.q_proj.weight', 'feature_extract.model.encoder.layers.8.self_attn.q_proj.bias', 'feature_extract.model.encoder.layers.8.self_attn.out_proj.weight', 'feature_extract.model.encoder.layers.8.self_attn.out_proj.bias', 'feature_extract.model.encoder.layers.8.self_attn.grep_linear.weight', 'feature_extract.model.encoder.layers.8.self_attn.grep_linear.bias', 'feature_extract.model.encoder.layers.8.self_attn_layer_norm.weight', 'feature_extract.model.encoder.layers.8.self_attn_layer_norm.bias', 'feature_extract.model.encoder.layers.8.fc1.weight', 'feature_extract.model.encoder.layers.8.fc1.bias', 'feature_extract.model.encoder.layers.8.fc2.weight', 'feature_extract.model.encoder.layers.8.fc2.bias', 'feature_extract.model.encoder.layers.8.final_layer_norm.weight', 'feature_extract.model.encoder.layers.8.final_layer_norm.bias', 'feature_extract.model.encoder.layers.9.self_attn.grep_a', 'feature_extract.model.encoder.layers.9.self_attn.k_proj.weight', 'feature_extract.model.encoder.layers.9.self_attn.k_proj.bias', 'feature_extract.model.encoder.layers.9.self_attn.v_proj.weight', 'feature_extract.model.encoder.layers.9.self_attn.v_proj.bias', 'feature_extract.model.encoder.layers.9.self_attn.q_proj.weight', 'feature_extract.model.encoder.layers.9.self_attn.q_proj.bias', 'feature_extract.model.encoder.layers.9.self_attn.out_proj.weight', 'feature_extract.model.encoder.layers.9.self_attn.out_proj.bias', 'feature_extract.model.encoder.layers.9.self_attn.grep_linear.weight', 'feature_extract.model.encoder.layers.9.self_attn.grep_linear.bias', 'feature_extract.model.encoder.layers.9.self_attn_layer_norm.weight', 'feature_extract.model.encoder.layers.9.self_attn_layer_norm.bias', 'feature_extract.model.encoder.layers.9.fc1.weight', 'feature_extract.model.encoder.layers.9.fc1.bias', 'feature_extract.model.encoder.layers.9.fc2.weight', 'feature_extract.model.encoder.layers.9.fc2.bias', 'feature_extract.model.encoder.layers.9.final_layer_norm.weight', 'feature_extract.model.encoder.layers.9.final_layer_norm.bias', 'feature_extract.model.encoder.layers.10.self_attn.grep_a', 'feature_extract.model.encoder.layers.10.self_attn.k_proj.weight', 'feature_extract.model.encoder.layers.10.self_attn.k_proj.bias', 'feature_extract.model.encoder.layers.10.self_attn.v_proj.weight', 'feature_extract.model.encoder.layers.10.self_attn.v_proj.bias', 'feature_extract.model.encoder.layers.10.self_attn.q_proj.weight', 'feature_extract.model.encoder.layers.10.self_attn.q_proj.bias', 'feature_extract.model.encoder.layers.10.self_attn.out_proj.weight', 'feature_extract.model.encoder.layers.10.self_attn.out_proj.bias', 'feature_extract.model.encoder.layers.10.self_attn.grep_linear.weight', 'feature_extract.model.encoder.layers.10.self_attn.grep_linear.bias', 'feature_extract.model.encoder.layers.10.self_attn_layer_norm.weight', 'feature_extract.model.encoder.layers.10.self_attn_layer_norm.bias', 'feature_extract.model.encoder.layers.10.fc1.weight', 'feature_extract.model.encoder.layers.10.fc1.bias', 'feature_extract.model.encoder.layers.10.fc2.weight', 'feature_extract.model.encoder.layers.10.fc2.bias', 'feature_extract.model.encoder.layers.10.final_layer_norm.weight', 'feature_extract.model.encoder.layers.10.final_layer_norm.bias', 'feature_extract.model.encoder.layers.11.self_attn.grep_a', 'feature_extract.model.encoder.layers.11.self_attn.k_proj.weight', 'feature_extract.model.encoder.layers.11.self_attn.k_proj.bias', 'feature_extract.model.encoder.layers.11.self_attn.v_proj.weight', 'feature_extract.model.encoder.layers.11.self_attn.v_proj.bias', 'feature_extract.model.encoder.layers.11.self_attn.q_proj.weight', 'feature_extract.model.encoder.layers.11.self_attn.q_proj.bias', 'feature_extract.model.encoder.layers.11.self_attn.out_proj.weight', 'feature_extract.model.encoder.layers.11.self_attn.out_proj.bias', 'feature_extract.model.encoder.layers.11.self_attn.grep_linear.weight', 'feature_extract.model.encoder.layers.11.self_attn.grep_linear.bias', 'feature_extract.model.encoder.layers.11.self_attn_layer_norm.weight', 'feature_extract.model.encoder.layers.11.self_attn_layer_norm.bias', 'feature_extract.model.encoder.layers.11.fc1.weight', 'feature_extract.model.encoder.layers.11.fc1.bias', 'feature_extract.model.encoder.layers.11.fc2.weight', 'feature_extract.model.encoder.layers.11.fc2.bias', 'feature_extract.model.encoder.layers.11.final_layer_norm.weight', 'feature_extract.model.encoder.layers.11.final_layer_norm.bias', 'feature_extract.model.encoder.layer_norm.weight', 'feature_extract.model.encoder.layer_norm.bias', 'feature_extract.model.layer_norm.weight', 'feature_extract.model.layer_norm.bias', 'layer1.conv.weight', 'layer1.conv.bias', 'layer1.bn.weight', 'layer1.bn.bias', 'layer1.bn.running_mean', 'layer1.bn.running_var', 'layer2.Conv1dReluBn1.conv.weight', 'layer2.Conv1dReluBn1.conv.bias', 'layer2.Conv1dReluBn1.bn.weight', 'layer2.Conv1dReluBn1.bn.bias', 'layer2.Conv1dReluBn1.bn.running_mean', 'layer2.Conv1dReluBn1.bn.running_var', 'layer2.Res2Conv1dReluBn.convs.0.weight', 'layer2.Res2Conv1dReluBn.convs.0.bias', 'layer2.Res2Conv1dReluBn.convs.1.weight', 'layer2.Res2Conv1dReluBn.convs.1.bias', 'layer2.Res2Conv1dReluBn.convs.2.weight', 'layer2.Res2Conv1dReluBn.convs.2.bias', 'layer2.Res2Conv1dReluBn.convs.3.weight', 'layer2.Res2Conv1dReluBn.convs.3.bias', 'layer2.Res2Conv1dReluBn.convs.4.weight', 'layer2.Res2Conv1dReluBn.convs.4.bias', 'layer2.Res2Conv1dReluBn.convs.5.weight', 'layer2.Res2Conv1dReluBn.convs.5.bias', 'layer2.Res2Conv1dReluBn.convs.6.weight', 'layer2.Res2Conv1dReluBn.convs.6.bias', 'layer2.Res2Conv1dReluBn.bns.0.weight', 'layer2.Res2Conv1dReluBn.bns.0.bias', 'layer2.Res2Conv1dReluBn.bns.0.running_mean', 'layer2.Res2Conv1dReluBn.bns.0.running_var', 'layer2.Res2Conv1dReluBn.bns.1.weight', 'layer2.Res2Conv1dReluBn.bns.1.bias', 'layer2.Res2Conv1dReluBn.bns.1.running_mean', 'layer2.Res2Conv1dReluBn.bns.1.running_var', 'layer2.Res2Conv1dReluBn.bns.2.weight', 'layer2.Res2Conv1dReluBn.bns.2.bias', 'layer2.Res2Conv1dReluBn.bns.2.running_mean', 'layer2.Res2Conv1dReluBn.bns.2.running_var', 'layer2.Res2Conv1dReluBn.bns.3.weight', 'layer2.Res2Conv1dReluBn.bns.3.bias', 'layer2.Res2Conv1dReluBn.bns.3.running_mean', 'layer2.Res2Conv1dReluBn.bns.3.running_var', 'layer2.Res2Conv1dReluBn.bns.4.weight', 'layer2.Res2Conv1dReluBn.bns.4.bias', 'layer2.Res2Conv1dReluBn.bns.4.running_mean', 'layer2.Res2Conv1dReluBn.bns.4.running_var', 'layer2.Res2Conv1dReluBn.bns.5.weight', 'layer2.Res2Conv1dReluBn.bns.5.bias', 'layer2.Res2Conv1dReluBn.bns.5.running_mean', 'layer2.Res2Conv1dReluBn.bns.5.running_var', 'layer2.Res2Conv1dReluBn.bns.6.weight', 'layer2.Res2Conv1dReluBn.bns.6.bias', 'layer2.Res2Conv1dReluBn.bns.6.running_mean', 'layer2.Res2Conv1dReluBn.bns.6.running_var', 'layer2.Conv1dReluBn2.conv.weight', 'layer2.Conv1dReluBn2.conv.bias', 'layer2.Conv1dReluBn2.bn.weight', 'layer2.Conv1dReluBn2.bn.bias', 'layer2.Conv1dReluBn2.bn.running_mean', 'layer2.Conv1dReluBn2.bn.running_var', 'layer2.SE_Connect.linear1.weight', 'layer2.SE_Connect.linear1.bias', 'layer2.SE_Connect.linear2.weight', 'layer2.SE_Connect.linear2.bias', 'layer3.Conv1dReluBn1.conv.weight', 'layer3.Conv1dReluBn1.conv.bias', 'layer3.Conv1dReluBn1.bn.weight', 'layer3.Conv1dReluBn1.bn.bias', 'layer3.Conv1dReluBn1.bn.running_mean', 'layer3.Conv1dReluBn1.bn.running_var', 'layer3.Res2Conv1dReluBn.convs.0.weight', 'layer3.Res2Conv1dReluBn.convs.0.bias', 'layer3.Res2Conv1dReluBn.convs.1.weight', 'layer3.Res2Conv1dReluBn.convs.1.bias', 'layer3.Res2Conv1dReluBn.convs.2.weight', 'layer3.Res2Conv1dReluBn.convs.2.bias', 'layer3.Res2Conv1dReluBn.convs.3.weight', 'layer3.Res2Conv1dReluBn.convs.3.bias', 'layer3.Res2Conv1dReluBn.convs.4.weight', 'layer3.Res2Conv1dReluBn.convs.4.bias', 'layer3.Res2Conv1dReluBn.convs.5.weight', 'layer3.Res2Conv1dReluBn.convs.5.bias', 'layer3.Res2Conv1dReluBn.convs.6.weight', 'layer3.Res2Conv1dReluBn.convs.6.bias', 'layer3.Res2Conv1dReluBn.bns.0.weight', 'layer3.Res2Conv1dReluBn.bns.0.bias', 'layer3.Res2Conv1dReluBn.bns.0.running_mean', 'layer3.Res2Conv1dReluBn.bns.0.running_var', 'layer3.Res2Conv1dReluBn.bns.1.weight', 'layer3.Res2Conv1dReluBn.bns.1.bias', 'layer3.Res2Conv1dReluBn.bns.1.running_mean', 'layer3.Res2Conv1dReluBn.bns.1.running_var', 'layer3.Res2Conv1dReluBn.bns.2.weight', 'layer3.Res2Conv1dReluBn.bns.2.bias', 'layer3.Res2Conv1dReluBn.bns.2.running_mean', 'layer3.Res2Conv1dReluBn.bns.2.running_var', 'layer3.Res2Conv1dReluBn.bns.3.weight', 'layer3.Res2Conv1dReluBn.bns.3.bias', 'layer3.Res2Conv1dReluBn.bns.3.running_mean', 'layer3.Res2Conv1dReluBn.bns.3.running_var', 'layer3.Res2Conv1dReluBn.bns.4.weight', 'layer3.Res2Conv1dReluBn.bns.4.bias', 'layer3.Res2Conv1dReluBn.bns.4.running_mean', 'layer3.Res2Conv1dReluBn.bns.4.running_var', 'layer3.Res2Conv1dReluBn.bns.5.weight', 'layer3.Res2Conv1dReluBn.bns.5.bias', 'layer3.Res2Conv1dReluBn.bns.5.running_mean', 'layer3.Res2Conv1dReluBn.bns.5.running_var', 'layer3.Res2Conv1dReluBn.bns.6.weight', 'layer3.Res2Conv1dReluBn.bns.6.bias', 'layer3.Res2Conv1dReluBn.bns.6.running_mean', 'layer3.Res2Conv1dReluBn.bns.6.running_var', 'layer3.Conv1dReluBn2.conv.weight', 'layer3.Conv1dReluBn2.conv.bias', 'layer3.Conv1dReluBn2.bn.weight', 'layer3.Conv1dReluBn2.bn.bias', 'layer3.Conv1dReluBn2.bn.running_mean', 'layer3.Conv1dReluBn2.bn.running_var', 'layer3.SE_Connect.linear1.weight', 'layer3.SE_Connect.linear1.bias', 'layer3.SE_Connect.linear2.weight', 'layer3.SE_Connect.linear2.bias', 'layer4.Conv1dReluBn1.conv.weight', 'layer4.Conv1dReluBn1.conv.bias', 'layer4.Conv1dReluBn1.bn.weight', 'layer4.Conv1dReluBn1.bn.bias', 'layer4.Conv1dReluBn1.bn.running_mean', 'layer4.Conv1dReluBn1.bn.running_var', 'layer4.Res2Conv1dReluBn.convs.0.weight', 'layer4.Res2Conv1dReluBn.convs.0.bias', 'layer4.Res2Conv1dReluBn.convs.1.weight', 'layer4.Res2Conv1dReluBn.convs.1.bias', 'layer4.Res2Conv1dReluBn.convs.2.weight', 'layer4.Res2Conv1dReluBn.convs.2.bias', 'layer4.Res2Conv1dReluBn.convs.3.weight', 'layer4.Res2Conv1dReluBn.convs.3.bias', 'layer4.Res2Conv1dReluBn.convs.4.weight', 'layer4.Res2Conv1dReluBn.convs.4.bias', 'layer4.Res2Conv1dReluBn.convs.5.weight', 'layer4.Res2Conv1dReluBn.convs.5.bias', 'layer4.Res2Conv1dReluBn.convs.6.weight', 'layer4.Res2Conv1dReluBn.convs.6.bias', 'layer4.Res2Conv1dReluBn.bns.0.weight', 'layer4.Res2Conv1dReluBn.bns.0.bias', 'layer4.Res2Conv1dReluBn.bns.0.running_mean', 'layer4.Res2Conv1dReluBn.bns.0.running_var', 'layer4.Res2Conv1dReluBn.bns.1.weight', 'layer4.Res2Conv1dReluBn.bns.1.bias', 'layer4.Res2Conv1dReluBn.bns.1.running_mean', 'layer4.Res2Conv1dReluBn.bns.1.running_var', 'layer4.Res2Conv1dReluBn.bns.2.weight', 'layer4.Res2Conv1dReluBn.bns.2.bias', 'layer4.Res2Conv1dReluBn.bns.2.running_mean', 'layer4.Res2Conv1dReluBn.bns.2.running_var', 'layer4.Res2Conv1dReluBn.bns.3.weight', 'layer4.Res2Conv1dReluBn.bns.3.bias', 'layer4.Res2Conv1dReluBn.bns.3.running_mean', 'layer4.Res2Conv1dReluBn.bns.3.running_var', 'layer4.Res2Conv1dReluBn.bns.4.weight', 'layer4.Res2Conv1dReluBn.bns.4.bias', 'layer4.Res2Conv1dReluBn.bns.4.running_mean', 'layer4.Res2Conv1dReluBn.bns.4.running_var', 'layer4.Res2Conv1dReluBn.bns.5.weight', 'layer4.Res2Conv1dReluBn.bns.5.bias', 'layer4.Res2Conv1dReluBn.bns.5.running_mean', 'layer4.Res2Conv1dReluBn.bns.5.running_var', 'layer4.Res2Conv1dReluBn.bns.6.weight', 'layer4.Res2Conv1dReluBn.bns.6.bias', 'layer4.Res2Conv1dReluBn.bns.6.running_mean', 'layer4.Res2Conv1dReluBn.bns.6.running_var', 'layer4.Conv1dReluBn2.conv.weight', 'layer4.Conv1dReluBn2.conv.bias', 'layer4.Conv1dReluBn2.bn.weight', 'layer4.Conv1dReluBn2.bn.bias', 'layer4.Conv1dReluBn2.bn.running_mean', 'layer4.Conv1dReluBn2.bn.running_var', 'layer4.SE_Connect.linear1.weight', 'layer4.SE_Connect.linear1.bias', 'layer4.SE_Connect.linear2.weight', 'layer4.SE_Connect.linear2.bias', 'conv.weight', 'conv.bias', 'pooling.linear1.weight', 'pooling.linear1.bias', 'pooling.linear2.weight', 'pooling.linear2.bias', 'bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'linear.weight', 'linear.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('models/wavlm_base_lora_finetune.pth'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.9165e-02, 1.9135e-02, 1.7029e-02,  ..., 6.1035e-05, 6.1035e-05,\n",
      "         6.1035e-05],\n",
      "        [1.9165e-02, 1.9135e-02, 1.7029e-02,  ..., 6.1035e-05, 6.1035e-05,\n",
      "         6.1035e-05]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0110, -0.0226, -0.0211,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0110, -0.0226, -0.0211,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 0.0388,  0.0301, -0.0053,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0388,  0.0301, -0.0053,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-6.4026e-02, -9.6375e-02, -1.1667e-01,  ...,  3.0518e-05,\n",
      "         -2.1362e-04,  6.4087e-04],\n",
      "        [-6.4026e-02, -9.6375e-02, -1.1667e-01,  ...,  3.0518e-05,\n",
      "         -2.1362e-04,  6.4087e-04]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-6.9214e-02, -7.7301e-02, -8.5449e-02,  ...,  9.1553e-05,\n",
      "         -1.5259e-04, -2.7466e-04],\n",
      "        [-6.9214e-02, -7.7301e-02, -8.5449e-02,  ...,  9.1553e-05,\n",
      "         -1.5259e-04, -2.7466e-04]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.1442, -0.1281, -0.0203,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.1442, -0.1281, -0.0203,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[0.0378, 0.0594, 0.0632,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0378, 0.0594, 0.0632,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 0.0026,  0.0021, -0.0003,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0026,  0.0021, -0.0003,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 0.0232, -0.0400, -0.1450,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0232, -0.0400, -0.1450,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0088, -0.0113, -0.0111,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0088, -0.0113, -0.0111,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0141, -0.0130, -0.0054,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0141, -0.0130, -0.0054,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 9.5825e-03,  6.6528e-03,  4.6082e-03,  ..., -9.1553e-05,\n",
      "         -1.5259e-04, -1.8311e-04],\n",
      "        [ 9.5825e-03,  6.6528e-03,  4.6082e-03,  ..., -9.1553e-05,\n",
      "         -1.5259e-04, -1.8311e-04]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0250, -0.0298,  0.0061,  ..., -0.0001, -0.0002,  0.0000],\n",
      "        [-0.0250, -0.0298,  0.0061,  ..., -0.0001, -0.0002,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[3.8727e-02, 4.7333e-02, 4.4647e-02,  ..., 1.2207e-04, 1.5259e-04,\n",
      "         3.0518e-05],\n",
      "        [3.8727e-02, 4.7333e-02, 4.4647e-02,  ..., 1.2207e-04, 1.5259e-04,\n",
      "         3.0518e-05]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 0.0045, -0.0054, -0.0102,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0045, -0.0054, -0.0102,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 2.1362e-04,  3.6621e-04,  4.2725e-04,  ..., -3.0518e-05,\n",
      "         -3.0518e-05,  0.0000e+00],\n",
      "        [ 2.1362e-04,  3.6621e-04,  4.2725e-04,  ..., -3.0518e-05,\n",
      "         -3.0518e-05,  0.0000e+00]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[0.0143, 0.0170, 0.0106,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0143, 0.0170, 0.0106,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0057,  0.0943,  0.2406,  ...,  0.0034,  0.0032,  0.0034],\n",
      "        [-0.0057,  0.0943,  0.2406,  ...,  0.0034,  0.0032,  0.0034]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[0.0117, 0.0182, 0.0201,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0117, 0.0182, 0.0201,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[0.0002, 0.0008, 0.0005,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0002, 0.0008, 0.0005,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 0.0009, -0.0101,  0.0003,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0009, -0.0101,  0.0003,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 0.0168,  0.0170,  0.0108,  ..., -0.0003, -0.0001, -0.0003],\n",
      "        [ 0.0168,  0.0170,  0.0108,  ..., -0.0003, -0.0001, -0.0003]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-9.9182e-03, -1.3153e-02, -5.2795e-03,  ...,  6.1035e-05,\n",
      "         -6.1035e-05,  0.0000e+00],\n",
      "        [-9.9182e-03, -1.3153e-02, -5.2795e-03,  ...,  6.1035e-05,\n",
      "         -6.1035e-05,  0.0000e+00]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 0.0291,  0.0114, -0.0002,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0291,  0.0114, -0.0002,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[2.4719e-03, 1.9836e-03, 2.4719e-03,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         3.0518e-05],\n",
      "        [2.4719e-03, 1.9836e-03, 2.4719e-03,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         3.0518e-05]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 0.0294,  0.0429,  0.0345,  ..., -0.0002, -0.0002, -0.0002],\n",
      "        [ 0.0294,  0.0429,  0.0345,  ..., -0.0002, -0.0002, -0.0002]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 3.7842e-03,  2.5452e-02,  7.1411e-03,  ...,  6.1035e-05,\n",
      "         -1.8311e-04, -2.4414e-04],\n",
      "        [ 3.7842e-03,  2.5452e-02,  7.1411e-03,  ...,  6.1035e-05,\n",
      "         -1.8311e-04, -2.4414e-04]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[0.0120, 0.0163, 0.0252,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0163, 0.0252,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 0.0140, -0.0295,  0.0904,  ..., -0.0002, -0.0003, -0.0001],\n",
      "        [ 0.0140, -0.0295,  0.0904,  ..., -0.0002, -0.0003, -0.0001]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[0.0053, 0.0056, 0.0021,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0053, 0.0056, 0.0021,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0064, -0.0057, -0.0025,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0064, -0.0057, -0.0025,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[0.0186, 0.0156, 0.0265,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0186, 0.0156, 0.0265,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0270, -0.0311, -0.0004,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0270, -0.0311, -0.0004,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-2.6337e-02, -2.8900e-02, -2.0447e-02,  ..., -6.1035e-05,\n",
      "          2.1362e-04,  2.7466e-04],\n",
      "        [-2.6337e-02, -2.8900e-02, -2.0447e-02,  ..., -6.1035e-05,\n",
      "          2.1362e-04,  2.7466e-04]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-3.2288e-02, -2.2461e-02, -3.3752e-02,  ...,  3.0518e-05,\n",
      "         -9.1553e-05, -2.1362e-04],\n",
      "        [-3.2288e-02, -2.2461e-02, -3.3752e-02,  ...,  3.0518e-05,\n",
      "         -9.1553e-05, -2.1362e-04]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 7.0190e-04,  1.3123e-03,  1.6785e-03,  ..., -3.0518e-05,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 7.0190e-04,  1.3123e-03,  1.6785e-03,  ..., -3.0518e-05,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 0.2328,  0.1283, -0.1161,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.2328,  0.1283, -0.1161,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 0.0026,  0.0026,  0.0018,  ...,  0.0006, -0.0002,  0.0001],\n",
      "        [ 0.0026,  0.0026,  0.0018,  ...,  0.0006, -0.0002,  0.0001]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0029, -0.0032, -0.0014,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0029, -0.0032, -0.0014,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0048, -0.0054, -0.0052,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0048, -0.0054, -0.0052,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0020, -0.0026, -0.0023,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0020, -0.0026, -0.0023,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0171, -0.0197, -0.0176,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0171, -0.0197, -0.0176,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[ 3.1708e-02,  3.4546e-02,  3.5706e-02,  ...,  3.0518e-05,\n",
      "         -3.0518e-05, -3.0518e-05],\n",
      "        [ 3.1708e-02,  3.4546e-02,  3.5706e-02,  ...,  3.0518e-05,\n",
      "         -3.0518e-05, -3.0518e-05]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[0.0069, 0.0085, 0.0052,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0069, 0.0085, 0.0052,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[0.0161, 0.0210, 0.0303,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0161, 0.0210, 0.0303,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0208, -0.0179, -0.0138,  ...,  0.0001,  0.0003,  0.0002],\n",
      "        [-0.0208, -0.0179, -0.0138,  ...,  0.0001,  0.0003,  0.0002]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[1.6083e-02, 2.1240e-02, 2.6367e-02,  ..., 6.1035e-05, 6.1035e-05,\n",
      "         9.1553e-05],\n",
      "        [1.6083e-02, 2.1240e-02, 2.6367e-02,  ..., 6.1035e-05, 6.1035e-05,\n",
      "         9.1553e-05]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-9.4604e-04,  1.2512e-03,  2.4719e-03,  ...,  6.1035e-05,\n",
      "          1.2207e-04, -6.1035e-05],\n",
      "        [-9.4604e-04,  1.2512e-03,  2.4719e-03,  ...,  6.1035e-05,\n",
      "          1.2207e-04, -6.1035e-05]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-1.2207e-04,  9.1553e-05, -1.5259e-04,  ..., -3.0518e-05,\n",
      "         -3.0518e-05, -6.1035e-05],\n",
      "        [-1.2207e-04,  9.1553e-05, -1.5259e-04,  ..., -3.0518e-05,\n",
      "         -3.0518e-05, -6.1035e-05]], device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n",
      "tensor([[-0.0015, -0.0033, -0.0012,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0015, -0.0033, -0.0012,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1662e-03,  9.9634e-04,  2.0860e-03,  4.8885e-04, -2.3666e-03,\n",
      "        -7.4487e-04,  1.5126e-03,  2.2123e-03,  7.0878e-03, -8.3986e-05],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "!!!!!\n"
     ]
    }
   ],
   "source": [
    "for idx, kv in enumerate(speaker_dict.items()):\n",
    "    k, wav = kv\n",
    "    \n",
    "    wav = torch.stack([wav, wav], dim=0)\n",
    "    wav = wav.to(device)\n",
    "    wav = wav.squeeze_(1)\n",
    "    \n",
    "    print(wav)\n",
    "    embed = model(wav)[0, ...]\n",
    "    \n",
    "    print(embed[:10])\n",
    "    \n",
    "    print(\"!!!!!\")\n",
    "    embed_matrix[idx, :] = embed\n",
    "    \n",
    "    speaker_id[idx] = speaker_list.index(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0032,  0.0010,  0.0021,  ..., -0.0016, -0.0004, -0.0019],\n",
       "        [-0.0032,  0.0010,  0.0021,  ..., -0.0016, -0.0004, -0.0019],\n",
       "        [-0.0032,  0.0010,  0.0021,  ..., -0.0016, -0.0004, -0.0019],\n",
       "        ...,\n",
       "        [-0.0032,  0.0010,  0.0021,  ..., -0.0016, -0.0004, -0.0019],\n",
       "        [-0.0032,  0.0010,  0.0021,  ..., -0.0016, -0.0004, -0.0019],\n",
       "        [-0.0032,  0.0010,  0.0021,  ..., -0.0016, -0.0004, -0.0019]],\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "pred_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(n_samples)):\n",
    "    sample_idx = random.randint(0, len(vox_mix) - 1)\n",
    "    wav_mix, wav_s1, wav_s2, sp1, sp2, _ = vox_mix[sample_idx]\n",
    "    \n",
    "    min_sz = min(wav_s1.shape[-1], wav_s2.shape[-1])\n",
    "    \n",
    "    if wav_s1.shape[-1] > min_sz:\n",
    "        wav_s1 = wav_s1[:, :min_sz]\n",
    "    if wav_s2.shape[-1] > min_sz:\n",
    "        wav_s2 = wav_s2[:, :min_sz]\n",
    "\n",
    "    pred_s1, pred_s2 = speaker_separation(sepformer, wav_mix)\n",
    "\n",
    "    \n",
    "    gt = torch.cat([wav_s1, wav_s2], dim=0).numpy()\n",
    "    pred = torch.cat([pred_s1, pred_s2], dim=0).numpy()\n",
    "    \n",
    "    min_sz = min(gt.shape[-1], pred.shape[-1])\n",
    "    \n",
    "    if gt.shape[-1] > min_sz:\n",
    "        gt = gt[:, :min_sz]\n",
    "    if pred.shape[-1] > min_sz:\n",
    "        pred = pred[:, :min_sz]\n",
    "        \n",
    "    \n",
    "    embeds = model(pred)\n",
    "    \n",
    "    cos_sim = F.cosine_similarity(embeds, embed_matrix, dim=1)\n",
    "    \n",
    "    cos_sim = cos_sim.cpu().numpy()\n",
    "    \n",
    "    idx = cos_sim.argmax()\n",
    "    \n",
    "    labels.append(speaker_id[idx])\n",
    "    pred_labels.append(sp1)\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7961\n"
     ]
    }
   ],
   "source": [
    "print(acc(model, [labels, pred_labels]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
